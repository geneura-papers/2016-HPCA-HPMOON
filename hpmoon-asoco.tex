\documentclass[preprint]{elsarticle}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{moreverb,url,color}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{color}
\usepackage{url}
%\usepackage{refcheck}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}

\newenvironment{bluecolor}{\par\color{blue}}{\par}


\begin{document}

\begin{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   TITLE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\journal{Applied Soft Computing}
\title{Distributed multi-objective evolutionary optimization using island-based selective operator application}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   AUTHORS   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{P. Garc\'ia-S\'anchez$^1$, J. Ortega$^2$, J. Gonz\'alez$^2$, P. A. Castillo$^2$ and J.J. Merelo$^2$}
\ead{pablo.garciasanchez@uca.es, \{jortega, jesusgonzalez, pacv, jmerelo\}@ugr.es}
\address{
$^1$ Department of Computer Science and Engineering. ESI. University of C\'adiz, Spain\\
$^2$ Department of Computer Architecture and Computer Technology.\\ ETSIIT - CITIC. University of Granada, Spain\\
}


\begin{abstract}



%One of the  most extensively used methods to deal with high-dimensional, multi-objective optimization problems are distributed co-evolutionary algorithms. However, only decomposable problems could strictly be implemented in parallel this way. A new parallel island-model evolutionary algorithm approach, which we call {\em selective operator application}, is used here to deal with un-decomposable problems: instead of sharing parts of individuals, each island, hosted by a single processor, applies the variation operators to a specific subset of the whole individual. This avoids extra steps to recompose the complete individuals from other islands before evaluation.

%In this paper, we intend to demonstrate that automatically setting the size of these  overlapping sections, since it focuses the search between borders of the different search spaces, is able to obtain better  results than using the same size independently of the number of islands. In order to demonstrate that, we  have compared this method to other parallel evolutionary techniques considering different number of islands, chromosome sizes and benchmarks. The analysis of the obtained experimental results, by using different metrics, shows that our approach can provide statistically significant improvements with respect to the base algorithm in high-dimensional, un-decomposable, multi-objective problems. 

%Results also show that the relation between the number of islands (subpopulations) and the length of the chromosome (number of decision variables) is also a relevant factor to determine the most efficient alternative to distribute the decision variables: the higher the dimensionality and the overlapping, the greater the benefit of distribution in a large number of islands. This opens up a new challenge to be addressed in the future, by experimenting with new ways to calculate the overlapping sizes depending of different factors and parameters.

%%%NEW AND SHORTED
Parallel island-model co-evolutionary algorithms are well-known
methods, suitable for dealing with large multi-objective optimization
problems. \textcolor{blue}{This paper proposes a version of these algorithms where} each island modifies a fragment of the
chromosome that encodes a possible solution to the
problem. \textcolor{blue}{The objective of this paper is} to
demonstrate that automatically setting the size of the overlapping
fragments depending on the number of islands obtains better results
than using \textcolor{blue}{a fixed overlapping} size. \textcolor{blue}{This method has been
  compared} to other parallel evolutionary techniques considering a
different number of islands, chromosome sizes and benchmarks. The
analysis of the obtained experimental results, by using different
metrics, shows that our approach can provide statistically significant
improvements with respect to the base algorithm in high-dimensional,
un-decomposable, multi-objective problems. This opens a very promising
line to automatically adapt the overlapping sizes in this kind of
algorithms.


\end{abstract}


\begin{keyword}
Multi-objective algorithms \sep NSGA-II  \sep distributed evolutionary algorithms \sep Island model
\end{keyword}

\end{frontmatter}





\section{Introduction}

% Maybe add a sentence explaining what problems are decomposable and which ones are not. - JJ
% Pablo: ok, done in blue
\begin{bluecolor}
One of the methods that are most extensively used  to deal with
high-dimensional, multi-objective optimization problems (MOPs) are
distributed co-evolutionary algorithms \cite{Gong15models}. However,
only decomposable problems \textcolor{blue}{--that is, the ones whose  domain can be divided into subsets to calculate their partial solutions and combine them to form the solution of the original problem--,} could strictly be implemented in parallel
this way. A new parallel island-model evolutionary algorithm approach
\cite{Alba02Parallelism} is used here to deal with un-decomposable
problems: \textcolor{blue}{instead of allocating disjoint subsets of components to the islands hosted by the available processors, it applies the variation operators only to the components  of the subset allocated to a given population, while keeping the rest of the components of the whole individual unaltered}. This avoids extra steps (and
subsequent communication overhead) to recompose the complete
individuals from other islands before evaluation. 
\end{bluecolor}


%1. MOP ARE
In MOPs, several \textcolor{blue}{independent}
objectives have to be simultaneously optimized
\citep{Mora13paretobased,LIU2017344}. Solving a MOP implies optimizing a function composed of several independent cost functions, one per objective. In
these problems the aim is to obtain a set of solutions that are better
than the rest considering all the objectives; this set is known as
the Pareto Front (PF). The solutions in this set are {\em non-dominated},
which means that there is no other solution that is equal or better
for all objectives. The objective of MOP algorithms is to find as many
solutions equally distributed in the Pareto Front as possible. In order to do that\textcolor{blue}{,} the
exploration of the search space must be very efficient, trying to
cover \textcolor{blue}{all} possible exploration paths at the same time. 

%2 COMPUTATION -> PARALLEL
This aspect of searching for non-dominated solutions, as well as, in
many cases, the size of the search space itself, implies a high demand
of computational time, leading to the proposal of parallel and distributed methods to solve them
\citep{Luna15Survey,Mukhopadhyay14Survey,Chavez15MO,Hidalgo16residualstress,KAUR2018183,XU2018268},
%3 ONE WAY IS TO USE MOEAS BECAUSE
one of which \textcolor{blue}{is} evolutionary algorithms (EAs)
\citep{DBLP:series/ncs/EibenS15}. EAs are bio-inspired meta-heuristics
that can be effectively used to find nearly optimal solutions for
optimization problems and are easily parallelizable, since they are
population-based. This means that creating a functionally equivalent parallel
version is as easy as distributing the population in communicating
computing nodes, which are usually called islands. The fact that
they are population-based helps find many solutions that compose the
Pareto front simultaneously.


Usually\textcolor{blue}{,} an EA starts by generating \textcolor{blue}{a \emph{population}, that is, a set of random solutions}, following a user-defined description. Then, it
evaluates each candidate solution, called \emph{individual}, assigning
it a \emph{fitness} \textcolor{blue}{vector, in the case of MOPs} that describes how good the individual is
\textcolor{blue}{solving} the target problem. New solutions are then generated by
the application of \emph{operators} that either mutate a single
solution or recombine different existing solutions. After each
iteration, called \emph{generation}, the least fit individuals are
removed, and the process continues until a user-defined stop condition
is met.

EAs \textcolor{blue}{were} extended to multi-objective optimization through quite a number of Multi-Objective Evolutionary Algorithms (MOEAs) \cite{TalbiUnified2018}.
One of the best known and \textcolor{blue}{highly} referenced MOEAs
\citep{Dorronsoro13superlinear} is the {\em 
  Non-dominated Sorting Genetic Algorithm} (NSGA-II)
\citep{Deb00NSGAII}. Classical genetic operators are applied to all
the individuals, which are divided into different ranks, based on 
dominance, to be selected for the next generations.

%4 BUT THE EASY PARALLELIZATION IS NOT NECESSARILY EFFICIENT

Different approaches have been used to parallelize EAs, as each individual can be considered as an
independent unit \citep{Alba13parallel,Gong15models}. Classic methods, such as the
global parallel EAs (Master-Slave), or the spatially structured
algorithms (Island model or Cellular EAs) have been applied
successfully in the past \citep{Folino03cellular,Alba02Parallelism}.
However, in the case of MOEAs, these
approaches \citep{Luna15Survey} need to deal with the whole solution set, the PF.
 This implies \textcolor{blue}{using} different distribution
and sharing mechanisms, as there exists a tradeoff between the speedup
achievable from parallelization and the need to globally recombine the
results to accurately identify the PF
\citep{Branke04Parallelizingcone}. \textcolor{blue}{This is also the case with the NSGA-II.} % Is that the case with NSGA? - JJ
% Please check the last question - JJ Pablo: done

Real-world MOPs usually require a high number of decision variables \cite{Zhang17DECAL,XU2018268}, 
meaning that the
MOEAs need to deal with large individuals \textcolor{blue}{representing those variables} and spend significant extra
time \textcolor{blue}{applying the} crossover, mutation and migration \textcolor{blue}{operators}.
% If this is the only justification, it should have been assessed at the end. It would be better if it was qualified, in the sense that more exploration is needed or something like that - JJ
Different authors have 
proposed methods to divide the decision space (the chromosome) to
improve the performance and solution quality. % Why should it improve quality? - JJ Pablo: look at the 2 new paragraphs sent by Julio below (between \begin{bluecolor})
In this aspect, the
co-evolution model is a dimension-distributed model where a 
high-dimensional problem is divided into lower dimensional ones
\citep{Gong15models,Tonda12cooperative}, and evolved separately. \textcolor{blue}{To evolve the individuals of a subpopulation, the processor where it has been allocated can operate according to two main alternatives.} One
example of the application of the \textcolor{blue}{first alternative} was described in
\citep{Kimovski15Parallel}. The method presented in that work involves
different workers that evolve sub-populations created and recombined
by a master process, which performs \textcolor{blue}{different alternatives for the recombination/cooperation of the subpopulations returned by worker processes}. A high
dimensional problem was used to compare these 
alternatives\textcolor{blue}{; also, i}n \citep{Dorronsoro13superlinear}, a distributed
co-evolutionary island model was used.  Although  both papers \textcolor{blue}{described}
significant speedups, only a \textcolor{blue}{small} number of nodes were
employed (8). However, when the number of islands is increased, the division
of \textcolor{blue}{the portion of chromosome assigned to a given island} becomes smaller, and the scalability
may be affected by obtaining lower quality solutions in the same
amount of time. \textcolor{blue}{Moreover, in this first alternative, each processor only works with the variables allocated to it of the individuals in its population. Thus, only whenever the cost function is decomposable in such a way that the variables allocated to different processors are not interdependent, the evaluation of the fitness of an individual in the population can be done by composing the cost evaluated separately by each processor from the values of the variables allocated to it. Otherwise, it has to be determined after composing the whole solution from the components allocated to each processor. In fact, different strategies to define the way to distribute the components into groups to be allocated to the available processors are required. They have been mainly defined according to three categories \cite{Jia19Coevo}: (1) static partitions of variables into groups; (2) random dynamic grouping that changes the variables among groups along the optimization process; and (3) learning-based dynamic grouping to distribute the components by applying techniques to detect the interdependence among variables along the process. }





%5 WE HAVE PROPOSED HPMOON



Another approach used to solve this kind of problems is the {\em
  SeLective operator Application} (SLA), presented in this paper, \textcolor{blue}{can be considered as the second alternative to evolve the individuals of a subpopulation}. In this case, each island
deals with the whole chromosome, but only modifies a fragment of it in
the crossover and mutation phase depending on the number of islands,
using the whole chromosome for fitness calculation. This allows \textcolor{blue}{dealing} with un-decomposable problems. 

\begin{bluecolor}
 Thus, in this second alternative, a suitable cooperation function must be defined to select the individuals for the new set of subpopulations. Nevertheless, the right approach would be to define a suitable procedure that implements an efficient cooperation strategy to improve the convergence and convergence rate of the parallel cooperative co-evolutionary procedure with respect to the base sequential optimization procedure. 

This way, the open issues are related to the search for strategies that mathematically determine convergence rates according to the cost function, and associate sampling distributions in the sequential and parallel co-evolutionary procedures including the effect of the communications providing not fully actualized components. 
\end{bluecolor}

In our previous work \citep{Garcia16hpmoon} \textcolor{blue}{this method was used} in a
preliminary experimental setup, although it is worth mentioning \textcolor{blue}{that its name and acronym is established} in this paper for the first time.
\textcolor{blue}{In that paper, it was shown}
that applying the variation operators only \textcolor{blue}{to} specific sections of the whole chromosome improves the quality of the solutions in the same computing time for a multi-objective island-based algorithm.
Moreover, instead of making every island focus on a disjoint subset of the
chromosome, the usage of overlapped (shared) sections of the
chromosome 
can improve the quality of the solutions 
when the number of islands is increased. In that paper, \textcolor{blue}{the results showed} that the most
adequate overlapping size may vary depending on a relation between the
number of islands and the individual size. However, it was a proof-of-concept, and the experiments
were conducted in a limited experimental system: mono-processor and
synchronous island model. 
This
motivate\textcolor{blue}{d} us to continue this research line using a more complete environment: a real cluster with up to 128 nodes, and a more \textcolor{blue}{extensive parameter evaluation}. %Again, "testing more stuff" is not a good motivation. You should try to address a specific research question that might have been raised in the previous paper - JJ
Besides comparing previous methods in this new experimental setup,  
a new method that automatically sets the size of the overlapped
sections depending on the number of available islands \textcolor{blue}{is proposed in this paper, and compared} with previous versions. 


%6 IN THIS PAPER WE WILL BE PROVING

The hypothesis of this paper is that the use of automatically calculated overlapped sections of the
chromosome for the SLA can improve the
quality of the solutions in the same computing time with respect to
the baseline, disjoint and partly overlapped methods. 
The size of the overlapped sections is calculated from  the number of available subpopulations in the multi-objective evolutionary algorithm, and tested in a real computational environment.


In order to demonstrate this claim, our new automatic method has been
compared against different overlapping island schemes: a
baseline version of a distributed NSGA-II \citep{Deb00NSGAII}, a
SLA version with disjoint sections and a SLA
fixed-size overlapped version. 
Several benchmark problems and different large number of islands
have been used. Results show that this new technique can improve
different quality indicators in the same amount of time when the
problem size is large.

% There's no mention of the type of the benchmark problems. Insert here some characterization, including whether they are epistatic or not - JJ

Results also show that the relation between the number of islands
(subpopulations) and the length of the chromosome (number of decision
variables) is also a relevant factor to determine the most efficient
alternative to \textcolor{blue}{distribute} the decision variables: the higher the
dimensionality and the overlapping, the greater the benefit of
distribution in a large number of islands. This opens up a new
challenge to be addressed in the future, by experimenting with new
ways to calculate the overlapping sizes depending on different factors
and parameters.

The rest of the paper is organized as follows: after the State of the Art in distributed and co-evolutionary MOEAs, 
the \textcolor{blue}{proposed} methodology and the compared algorithms are described in Section \ref{sec:methodology}. 
Then, the results of the experiments are presented (Section \ref{sec:results}), Finally, the conclusions and future work are discussed.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  STATE OF THE ART  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{State of the Art}
\label{sec:soa}

%FERGU: Texto que me ha pasado Julio
%\textcolor{blue}{Multi-objective optimization evolutionary algorithms (MOEAs) can take advantage of parallel and distributed processing \cite{Gong15models} not only to improve the quality of the solutions found, but also to speed up the execution times. Among the functional and data decomposition alternatives to parallelize an algorithm, parallel evolutionary algorithms usually implement data decomposition by identifying tasks that have to be repeatedly executed on different data. For example, in an evolutionary algorithm, the evaluation of the fitness function and the application of mutation operators to the individuals of the population can be independently applied to each individual. Moreover, in the context of data decomposition, two main alternatives can be distinguished. In the first one, the individuals of the population are distributed among several processes that independently compute their corresponding fitness functions. Once each process completes the fitness evaluation of the individuals allocated to it, another process applies the corresponding evolutionary operators to the individuals of the whole population to determine the population for the next generation. Then, the population is distributed again among the processes to obtain the new values of the fitness and so on until the end condition (a given number of generations, or a solution quality level) is met. It is clear that this alternative does not modify the convergence characteristics of the corresponding sequential evolutionary algorithm, although to complete each iteration communication is required between the process that applies the evolutionary operators to the population and the processes that evaluate the fitness values of the population. In the second alternative, several parallel processes execute iterations of the corresponding evolutionary algorithm on different subpopulations. In this case, the convergence behaviour could be different in sequential and parallel versions of the algorithms as the different subpopulations evolve in parallel and only exchange information about their individuals after completing a given number of generations. The number of individuals in the subpopulations (the grain size of the parallel procedure), and the characteristics of the communication (frequency of communication, character synchronous or asynchronous of the communication, characteristics of the communicated data, etc.) determine the performance of the parallel procedure. This second parallelization alternative (concurrent execution of evolutionary algorithms over multiple subpopulations) is the one considered in this paper. It can be implemented either by a master-worker approximation or by assigning each subpopulation to a different processor and communicating this processor with the others when it is required. In this second approach, according to the size of the grain (number of individuals in the subpopulations), two main alternatives can be also distinguished: the island parallel approach (coarse grain) and the cellular or diffusion approach (fine grain). In the master-worker approximation, the master distributes the subpopulations among the workers that communicate through the master. This way, as the communications increase (with the number of subpopulations and/or the frequency of communications among subpopulations) the master could become a bottleneck that reduces the efficiency of the parallel procedure.}



Since the early 2000s distributed and parallel EAs
 have been used mostly to leverage systems such
as clusters or grids \citep{Talbi08Parallel}, since a first-order
approach to EA parallelization is as easy as dividing the population
and add a simple communication mechanism among them. But in the case of
MOEAs, the distribution and parallelization are more difficult than in
single-objective EAs. This is because in different steps of the
algorithm a whole set of dependent solutions, the Pareto Front, should
be managed as a whole, spending time in gathering all individuals from
the different processors or islands. 

To solve this issue, some authors have proposed using Master-Slave approaches. For example,  \citep{Durillo08masterslave} compared different master-slave approaches: synchronous generational, asynchronous generational and asynchronous steady-state, being the latter the most promising option. On the other hand, the method proposed by Hiroyasu \citep{Hiroyasu07discussion} generates offspring depending on the computational power.

%This is an improvement over the previous? What is the relationship? FERGU: linked
Other \textcolor{blue}{kinds} of approaches have also been explored. The work by Deb et al. \citep{Deb03distributed} was one of the first approaches for distributed MOEAs (dMOEAs). In that work, the dominance of the solutions was divided into the islands using a coordinate transformation. In that paper, the authors concluded that dividing the search space is a good idea, although achieving this is not trivial. The division of the search space has been explored by other researchers, for example, dividing the population into elite and search sub-populations \citep{Wang09parallel}, or separating it \textcolor{blue}{into} processors by objective \citep{Xiao03specialized}. For example, in \cite{Zhang17DECAL}, a weighted function is used to decompose the objective function and every subpopulation is responsible to solve the problem defined by a weighted vector. Other authors, such as M{\"a}rtens \citep{Martens13asynchronous} use migration to accept individuals based on diversity, and migrating from not-crowded areas.

% Is this really cooperative co-evolution? - JJ FERGU: You mean the Dorronsoro one? The title says it
Many real-world problems \textcolor{blue}{require} high-dimensional data \cite{Zhang17DECAL,XU2018268}.
Addressing this kind of problems with cooperative co-evolution has
also been studied in several works with approaches closer to the one
presented here. The approach to focus on a portion of the chromosome,
as in our overlapped method, was firstly used in the work by
Dorronsoro et al. \citep{Dorronsoro13superlinear}, obtaining
super-linear performance 
in several instances. Recently, this approach has also been tested using a Particle Swarm Optimization (PSO) algorithm \cite{DorronsoroPSO2018}, also obtaining significant improvements in speedups and solution quality. Other authors, such as Cao et al. \cite{CaoZLL17} separate the decision variables into several subpopulations after performing an interdependence analysis, but using a fixed number of processors.

The approach described by Dorronsoro et al. has also been used by Kimovski et al. \citep{Kimovski15Parallel}, but implementing a
master-slave method that splits the population into several processors. As in previous works, each node
runs a parallel MOEA that only affects some portion of 
the individuals and the master
process receives all the sub-populations to be combined every certain number of generations. Up to 8 processors
were used in the experimental setup, and several
combination alternatives were compared. The main difference of our work with respect to previous works is that our approach does not 
broadcast all solutions to all islands for recombination, but only one solution to a random island, needing less
communication time. Moreover, Dorronsoro or Kimovsky approaches limited the maximum number of islands to 8, while in this paper \textcolor{blue}{up to 128 islands have been used}. 

Giving the responsibility of different parts of the search space to
different modules, has also been explored lately by some
researchers. For example, some authors focus on the solution space
\textcolor{blue}{modelling} the PF by dividing it into different clusters, allowing an
easily parallelizable {\em divide and conquer} approach
\citep{cheng2015adaptive}. 
Even other types of metaheuristics, 
such as the Multi-Objective Ant Colony Optimization (MOACO) \cite{Mora13paretobased}
or Artificial Bee Colony Algorithm \cite{LUO2017235}, 
can rely on island models to divide the search space depending on 
the node to achieve better results.

In our previous work \citep{Garcia16hpmoon} some of
the aforementioned ideas \textcolor{blue}{were used} to compare two different dMOEAs. The first
one divided the chromosome into $P$ sections,  \textcolor{blue}{with} $P$ being the number of
islands. Every island $p$ only performed the mutation and crossover in
that part ($p_{th}$) of the chromosome (the selective operator application), while the fitness was
calculated using the whole individual. After a certain number of
generations, individuals were migrated randomly to other islands. The
performance metrics were calculated at the end of the run. The second
method, selective operator application with overlapping islands, used the $p_{th-1}$ and
$p_{th+1}$ sections of each chromosome, besides the $p_{th}$
part. During the same amount of time, both methods obtained better
results than a baseline algorithm that dealt with the whole chromosome
in each island for crossover and mutation. \textcolor{blue}{It was} discovered \textcolor{blue}{in that paper} that the
performance using one or another method depends on \textcolor{blue}{both} the number of
sections \textcolor{blue}{individual's section used by each island} and the number of islands. This
motivated us to find a new automatic method to select this number of
sections of the chromosome to \textcolor{blue}{be used}, depending on the number of
islands. Besides, previous experiments were performed on a single
processor \textcolor{blue}{with a} synchronous island model and a limited number of islands
(8, 32 and 128). In this paper,  8, 16, 32, 64 and 128 islands have
been used, and \textcolor{blue}{this time}, the experiments have been run on a parallel
cluster. 
Therefore, at the same time, \textcolor{blue}{a new method is proposed in this paper} to divide the individual search space according to the number of \textcolor{blue}{evolving} subpopulations, and also validating the previous approach.


%We will describe how we have tested our approach in the next Section.
\textcolor{blue}{The methodology to test our approach is described in the next Section.}




%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  METHODOLOGY  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\section{Methodology} 
\label{sec:methodology}

The objective of this section is to explain the methodology followed to
compare the different versions of the overlapping schemes.

\subsection{Proposed methods}
 \textcolor{blue}{Several implemented SLA algorithms are analyzed in this paper}
 by using a parallel multi-objective baseline algorithm
as a basis for comparisons. Our proposed methods, using different overlapping schemes, 
are based on NSGA-II, as almost all the previous works discussed
before
\cite{Dorronsoro13superlinear,Durillo08masterslave,Hiroyasu07discussion,Deb03distributed,Xiao03specialized,Wang09parallel,Martens13asynchronous}. 
Therefore, a basic distributed NSGA-II algorithm without
overlapping sections \textcolor{blue}{has been used as the baseline option} (B).


This basic distributed algorithm spreads the population among $P$
islands; after a fixed number of generations,
one individual in a given island is migrated to another random island,
thus avoiding to synchronize the global PF every
certain number of generations as other methods described in Section 2
do. At the end of the run, the PFs of all islands are
aggregated into a new one, and the quality measures are evaluated. 
Different  SLA alternatives can be devised to evolve the
subpopulations according to the decision space to be explored by each
island. Here three methods \textcolor{blue}{will be considered} in which each island only
performs crossover and mutation in specific sections of the
individuals. 



%This algorithm is a regular NSGA-II algorithm distributed along a number $P$ of islands. After a fixed number of generations, one individual is migrated to another random island. At the end of the run, PFs of all islands are aggregated in a new one in order to compute the quality measures. This baseline method has been chosen as it does not require synchronization of the global PF every certain number of generations, as other methods described in Section 2 do.
%% some justification on why this was chosen - JJ PABLO: Added 
%
%% And some liaison to next subsection - JJ
%This method will be compared to different co-evolutionary approaches that are similar to the baseline, with the exception on the decision space to explore in each island.
%Three different co-evolutionary methods have been used. In all these methods, each island only performs crossover and mutation in specific sections of the individuals.

As in the baseline \textcolor{blue}{method} (B), an individual is migrated to another random
island after a fixed number of generations. In the \textcolor{blue}{destination} island, this \textcolor{blue}{new}
individual will be considered as \textcolor{blue}{one more individual in the subpopulation, being}
crossed and mutated in the same way, depending on the island
identifier (from 1 to $P$). Note that, unlike the other works such as the ones
described by Talbi et al. \citep{Talbi08Parallel}, all the islands deal
with complete chromosomes for fitness calculation, so our approach can
deal with decomposable and no decomposable problems. 

The methods tested \textcolor{blue}{in this paper} are presented in the next subsections. 

\subsubsection{SLA with disjoint islands (D)} 
In this approach, each individual of size $L$ is split into $P$ chunks
of size $L/P$. Every island $p$ only performs crossover and mutation
on the $p_{th}$ part of the individuals. Figure \ref{fig:disjoint}
describes this approach.
%
\begin{figure*}[h!tb]
\centering
\includegraphics[width=12cm]{islandDisjoint.jpg}
\caption{SLA with disjoint islands (D): every island $p$ only modifies the $p_{th}$ components (in grey) of the individuals using genetic operators (crossover and mutation). Also, every island evaluates its own individuals using the complete chromosome. After a given number of generations, it cooperates with the other islands through migration.}
\label{fig:disjoint}
\end{figure*}

\subsubsection{SLA with overlapping islands (O)}
This approach is similar to the previous one, but every island also uses the $p+1$ and $p-1$ (module size) chunks of the individual for crossover and migration. Therefore, some kind of overlapping of the crossed and mutated parts exists between islands. Figure \ref{fig:overlapping} shows the affected parts of the individuals in
each island. 

\begin{figure*}[h!tb]
\centering
\includegraphics[width=12cm]{islandNoDisjoint.jpg}
\caption{SLA with overlapping islands (O): every island $p$ modifies the  $p+1$,
  $p_{th}$ and $p-1$  components (in grey) of the individuals using genetic operators (crossover and mutation). Also, every island evaluates its own individuals using the complete chromosome. After a given number of generations, it cooperates with the other islands through migration.}
  \label{fig:overlapping}
\end{figure*}

\subsubsection{Automatic SLA with overlapping islands (A)} 
As in the previous method, the sections \textcolor{blue}{managed} by the operators are overlapped, but
instead of using one extra section on each side of the $p$ section ($p+1$
and $p-1$), it uses $c$ fragments on each side ($p+c$ and $p-c$),
being $c$ a value depending on the number of islands.

As a first
approach to automatically calculate this value, the results shown in
\citep{Garcia16hpmoon} have been used as a base to obtain $c$. In that
work, the overlapped method ($c=1$) obtained better results when the
number of islands was bigger than 8. On the contrary, when the number of
islands is small, no overlapping is necessary. So, this
knowledge \textcolor{blue}{has been used} to propose the formula $c=round(0.2*P-1)/2$ to calculate the
extra sections to overlap. Therefore, when $P=8$ then $c=0$
(equivalent to D), when $P=16$ then $c=1$ (equivalent to O), and so
on. Dividing individuals by blocks of equal size, instead of a percentage, allow the future integration of our method with other recombination mechanisms, such as the ones presented in \cite{Dorronsoro13superlinear} or \cite{Kimovski15Parallel}.
Also, as mentioned \textcolor{blue}{before}, this is only a \textcolor{blue}{naive approximation} to reach above-described behaviour for $c$, and future work will study new methods or alternative formulas to determine it, for example using Taguchi Method \cite{Keratmatpour2018Taguchi}.  Figure \ref{fig:adaptive} explains the $A$ method, assuming that $c=2$, for example. 

\begin{figure*}[h!tb]
\centering
\includegraphics[width=12cm]{islandAdaptive.jpg}
\caption{Automatic SLA with overlapping islands (A): every island $p$ modifies the  $p+c$,
  $p_{th}$ and $p-c$  components (in grey) of the individuals using genetic operators (crossover and mutation). Also, every island evaluates its own individuals using the complete chromosome. After a given number of generations\textcolor{blue}{,} it cooperates with the other islands through migration.} $c$ is calculated depending on the number of islands. In this case, $c=2$.
  \label{fig:adaptive}
\end{figure*}
% --------------------------------------------------------------

\textcolor{blue}{The} pseudo-code of the proposed algorithms is described in Algorithm \ref{alg:EA}.

\begin{algorithm}[htb]

\begin{algorithmic}
\STATE \textit{//In each island $i$}
\STATE population $\gets$ initialisePopulation()
\STATE \textit{//Select which part modify in this island $i$}
\STATE section $\gets$ getComponentsToModify($i$)
\IF {type = Baseline}
	\STATE $c=P/2$
\ELSIF {type = Disjoint}
	\STATE $c=0$
\ELSIF {type = Overlapping}
	\STATE $c=1$
\ELSIF {type = Automatic}
	\STATE $c=round(0.2*P-1)/2$
\ENDIF

\WHILE {stopping criterion not met}
    \STATE parents $\gets$ nsgaSelection(population)
    \FORALL{each 2 chromosome in parents}
    	\STATE \textit{//Crossovers only the part for island $i$ (c components left and right)}
    	\STATE children  $\gets$ crossover(parentA[i-c:i+c],parentB[i-c:i+c])
    	\STATE offspring $\gets$ offspring + children
    \ENDFOR
    \FORALL{chromosome in offspring}
    	\IF {mutationProb $>$ random()}
    		\STATE \textit{//Mutates only the part for island $i$}
    		\STATE chromosome $\gets$ mutation(chromosome[i-c:i+c])
    		\STATE offspring $\gets$ chromosome + offspring
    	\ENDIF
    \ENDFOR
    \STATE population $\gets$ population + offspring
    

    \IF {time to migrate}
      \STATE migrants $\gets$ binaryTournament(population)
      \STATE remoteBuffer $\gets$ getRandomIslandBuffer()
      \STATE remoteBuffer.send(migrants)
    \ENDIF

    \IF {localBuffer.size $\neq$ zero}
      \STATE immigrants $\gets$ localBuffer.read()
      \STATE population $\gets$ population + immigrants
    \ENDIF
\ENDWHILE

\STATE sendIslandParetoFrontToServer()
\STATE \textit{Final Pareto Front from all islands is returned by the server}
\end{algorithmic}

\caption{Pseudo-code of the used EA in every island: a distributed NSGA-II algorithm }
\label{alg:EA}
\end{algorithm}



%%%%%%%%%%%%%%%%%%%%%%%%%%  EXPERIMENTS AND RESULTS  %%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Experimental setup}

% Some introduction. ... We will describe here the design of the
% experiments bla bla bla--- JJ Pablo: Done
\textcolor{blue}{The design of the experiments is described in this subsection, starting with the measurements of quality, the benchmark problems, the different configurations compared, and the specific parameter set used.}

% Move this to the top - JJ Pablo: Done
\textcolor{blue}{Three different quality metrics have been used in this paper. These metrics have been chosen} not only because they have been used
extensively, especially in some of the papers presented in Section \ref{sec:soa}
\cite{Dorronsoro13superlinear,Durillo08masterslave,Hiroyasu07discussion,Wang09parallel,Martens13asynchronous},
but also because they cover different quality criteria. \textcolor{blue}{The} mathematical
formulation of these metrics can be found in
\cite{Dorronsoro13superlinear}.


\begin{itemize}
\item Hypervolume (HV): measures the area formed by all non-dominated solutions found with respect to a reference point. Higher values imply better quality of the PF. Figure \ref{fig:hypervolume} clarifies how the hypervolume is calculated.
\item Inverted Generational Distance (IGD): calculates the distance of the obtained set of solutions to the optimal PF. Therefore, this metric requires the optimal PF found in the literature, or the theoretical one. In this metric, the lower the better.
\item Spread (S): Measures the spread between solutions, taking into account the Euclidean distance between consecutive solutions. As in \textcolor{blue}{the} previous metric, the lower the value, the better, as it implies solutions distributed along all the PF.
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=6cm]{hypervolume.jpg}
\caption{Hypervolume calculation. Areas from Pareto Front solutions (black points) to a reference point (white point) are used to calculate the value of the hypervolume (all the gray area)}.
\label{fig:hypervolume}
\end{figure}




%\subsection{Benchmark problems}


The previously described four approaches have been run with two
different chromosome lengths ($L$): 512 and 2048. \textcolor{blue}{A} different number of
islands ($P$) have also been compared: 8, 16, 32, 64 and 128. This
maximum number of islands has also been  used in a previous work in the
literature \cite{Martens13asynchronous}. \textcolor{blue}{The chosen operators, SBX crossover and polynomial mutation, have also been  used previously by other
authors in \cite{Durillo08masterslave,CaoZLL17}, as its effectiveness has been demonstrated in this type of problems}.  % SBX is first mentioned
% here. Has to explain - JJ
% Still not done - JJ
% Pablo: Done, check if this is enough

ZDT \citep{zdt2000a} has been chosen as the benchmark, since it is the
most widely used \textcolor{blue}{one} in this area
\citep{Deb03distributed,Martens13asynchronous,Wang09parallel,Durillo08masterslave}. This
benchmark includes several functions, with different features that are
representative of real-world optimization problems. \textcolor{blue}{The} mathematical
formulation of each function is available in \citep{zdt2000a}. \textcolor{blue}{Please
note that the ZDT problems are non-epistatic, so in principle, our
conclusions should be extensible only to multiobjective problems with
the same nature.}


The global population size \textcolor{blue}{has been} set to 1024. \textcolor{blue}{That value has been chosen} for two reasons: the first is that it is large enough to have 8 individuals per island by dividing that number when using 128 islands and small enough to have 128 individuals when using 8 islands. This is the minimum and maximum population size per island used by M{\"a}rtens et al. in his work \cite{Martens13asynchronous}.


The criterion used for terminating an experiment has been the running
time: 25 seconds for dimension 512 and 100s (four times more) for
2048. According to Alba and Luque \cite{EVALUATIONPARALLEL}, other stop criteria such as the number of evaluations required to attain a solution, may be misleading depending on the studied scenario. In our case, \textcolor{blue}{the time has been used} instead of the number of evaluations firstly
because our hypothesis argues that the time saved in crossover and
mutation can be spent on improving the sub-populations and more
operations and migrations can be achieved. Also, 
different numbers of islands \textcolor{blue}{have been used} (with different sub-population sizes) and that
could lead to different execution times, so it would be difficult to
compare different times and quality of solutions at the same time.

The number of generations between migrations has been set to 5,
as
reported by \cite{Deb03distributed,Martens13asynchronous}. In general
and as affirmed by 
\cite{cantu1998survey}, the migration gap has contradictory effects
on the result: by increasing it, the system \textcolor{blue}{is made} closer to a
single-node one, since populations tend to mix without restriction; by
decreasing it, the \textcolor{blue}{isolated} islands \textcolor{blue}{are} more prone to being stuck
in local minima. \cite{Martens13asynchronous} mentions that several
values were tested with no influence in the result; in our particular
case, the mixing is essential for the algorithm to spread the result
to all parts of the chromosome. So, while \textcolor{blue}{one might} tend to agree with
M{\"a}rtens on the small influence of this value on the result, \textcolor{blue}{it is possible} that making this value much bigger in our case would have a
negative impact. However, a precise fine-tuning of this value is left
as future work, as the main focus of this paper was to show the
general concept, and not \textcolor{blue}{the tuning of} the values for maximum performance.

This migration
  is performed asynchronously, as it has the advantage of being a
  non-blocking operation \cite{TalbiUnified2018}. The individual
  chosen to migrate is selected from the subpopulation using Binary
  Tournament from a randomly selected couple, as proposed in previous papers
  \cite{xiong2003parallel,Xiao03specialized}. Whenever an island
  starts the migration step, the migrated individual is sent to
  another randomly selected island. \textcolor{blue}{This makes possible the} 
  dissemination of the modified parts of the individuals among the
  whole set of islands, thus avoiding a specific synchronization step
  to compose solutions obtained by different islands, as occurs \textcolor{blue}{in} other
  works \cite{Dorronsoro13superlinear}. The main parameters studied in the proposed system are limited to the number of islands and the size of the problem. This decision has been motivated because all previous works described in the state of the art also limit their experimental setting to the same parameters \cite{CaoZLL17,Dorronsoro13superlinear,DorronsoroPSO2018,Martens13asynchronous,Durillo08masterslave}. Although all the parameters indicated above have an influence on the general result of the MOEA, their general effect is well understood and, although there will be an interplay between them and the number of islands and problem size, this is left mainly as future work.






\begin{table*}[htb]
\begin{center}
\begin{tabular}{|c|c|}
\hline
{\em Parameter Name} & {\em Value} \\ \hline
Global population size ($N$) & 1024 \\ \hline
Selection type & Binary Tournament Selection \\ \hline
Replacement type & Generational \\ \hline 
Crossover type & SBX \\ \hline
Mutation  type & Polynomial\\ \hline
Mutation probability & 1/$L$ \\ \hline
Individuals per migration & 1 \\ \hline
Generations between migration & 5 \\ \hline
Selection for migration & Binary Tournament\\ \hline
Runs per configuration & 30 \\ \hline \hline
Number of islands ($P$) & 8, 16, 32, 64 and 128 \\ \hline
Chromosome size ($L$) & 512 and 2048 \\ \hline
Execution time (s) & 25 (for 512) and 100 (for 2048) \\ \hline \hline
\end{tabular}
\caption{Parameters and operators used in the experiments.}
\label{tab:parameters}
\end{center}
\end{table*}

The ECJ framework \citep{ECJ} has been used to run the
experiments, including its own random number generation implementation.  The specific modifications to deal with the proposed approaches have been developed as new modules for
ECJ, and their source code can be downloaded from our GitHub repository under \textcolor{blue}{an}
LGPL V3 License
\footnote{\url{https://github.com/hpmoon/hpmoon-islands}}. The quality metrics (HV, Spread and IGD) have been calculated using the jMetal \cite{Durillo11Jmetal} library.

The
island model has been executed asynchronously, using the ECJ distributed inter-population exchange
 model, in a cluster of 16 nodes, each one with 16 Intel(R) Xeon(R) CPU E5520
@2.27GHz processors, 16 GB RAM, Broadcom NetXtreme II BCM5716 1000Base-T (C0) PCI Express network cards, CentOS 6.8 and Java Version 1.8.0\_80. Islands are allocated to nodes in a round-robin way. That means that, for example, running with 8 islands requires 8 different nodes, instead of using several cores of a single node.

\section{Results}
\label{sec:results}


Different metrics, previously explained, have been used
to calculate the quality of the obtained PFs in every configuration. As HV requires a reference point to be
calculated (see Figure \ref{fig:hypervolume}), the value (1,9) \textcolor{blue}{has been chosen} as none of the existing solutions on all fronts obtained during all executions are dominated by it. In other words, as both objectives \textcolor{blue}{are being minimized}, this reference point is required to be numerically larger or equal in each objective, and strictly larger in at least one of them (dominated) for all solutions in the PFs \textcolor{blue}{used to be measured}. HV is then
normalized with respect to that point. Also, the optimal reference PF distribution used to calculate the IGD and Spread metrics \cite{Durillo11Jmetal} has 1000 solutions \footnote{Optimal PFs are available at:   \url{http://www.tik.ee.ethz.ch/sop/download/supplementary/testproblems/}.} .  
A Kruskal-Wallis significance
test has been performed to the metrics of all runs of the
configurations, as the Kolmogorov-Smirnov test detected non-normal
distributions.
%
\begin{table*}
\centering
\resizebox{14cm}{!}{
\begin{tabular}{|c||c|c|c|c||c|c|c|c||c|c|c|c||}
\hline
	&	\multicolumn{4}{|c|}{HV}													&	\multicolumn{4}{|c|}{Spread}														&	\multicolumn{4}{|c|}{IGD}														\\ \hline
%\multicolumn{13}{|c|}{2048 dimenOionO}																																													\\ \hline
\#Islands	&	B		&	D		&	O			&	A			&	B		&	D			&	O			&	A			&	B		&	D		&	O		&	A					\\ \hline
\multicolumn{13}{|c|}{ZDT1}																																													\\ \hline
8	&	0.900		&	0.816		& \textbf{	0.926	}		&	Equiv-D			& \textbf{	0.729	}	&	1.041			&	0.898			&	Equiv-D			&	0.013		&	0.029		& \textbf{	0.007	}	&	Equiv-D					\\
16	& \textbf{	0.880	}	&	0.675		&	0.839			&	Equiv-O			& \textbf{	0.721	}	&	0.897			&	0.983		D	&	Equiv-O			& \textbf{	0.017	}	&	0.062		&	0.025		&	Equiv-O					\\
32	& \textbf{	0.829	}	&	0.618		&	0.698			&	0.790			& \textbf{	0.763	}	&	0.879			&	0.886		D	&	0.913	DO		& \textbf{	0.027	}	&	0.076		&	0.056		&	0.036					\\
64	& \textbf{	0.769	}	&	0.596		&	0.628			&	0.736			& \textbf{	0.820	}	&	0.897			&	0.872			&	0.890	DO		& \textbf{	0.040	}	&	0.080		&	0.071		&	0.047					\\
128	& \textbf{	0.707	}	&	0.585		&	0.598			&	0.668			& \textbf{	0.850	}	&	0.956			&	0.883			&	0.910	O		& \textbf{	0.053	}	&	0.083		&	0.079		&	0.062					\\ \hline
\multicolumn{13}{|c|}{ZDT2}																																													\\ \hline
8	&	0.830		&	0.786		& \textbf{	0.851	}		&	Equiv-D			& \textbf{	0.866	}	&	0.996			&	0.987		D	&	Equiv-D			&	0.023		&	0.037		& \textbf{	0.017	}	&	Equiv-D					\\
16	& \textbf{	0.810	}	&	0.601		&	0.776			&	Equiv-O			& \textbf{	0.916	}	&	0.990			&	1.005		D	&	Equiv-O			& \textbf{	0.029	}	&	0.091		&	0.040		&	Equiv-O					\\
32	& \textbf{	0.756	}	&	0.498		&	0.617			&	0.682			& \textbf{	0.976	}	& \textbf{	0.976	}	B	& \textbf{	0.978	}	BD	&	1.054			& \textbf{	0.045	}	&	0.119		&	0.086		&	0.068					\\
64	& \textbf{	0.668	}	&	0.451		&	0.504			&	0.601			&	1.002		& \textbf{	0.976	}		& \textbf{	0.974	}	D	&	1.025	B		& \textbf{	0.070	}	&	0.132		&	0.117		&	0.091					\\
128	& \textbf{	0.576	}	&	0.434		&	0.452			&	0.526			&	1.002		&	1.023			& \textbf{	0.978	}		&	1.015	BD		& \textbf{	0.096	}	&	0.137		&	0.132		&	0.110					\\ \hline
\multicolumn{13}{|c|}{ZDT3}																																													\\ \hline
8	&	0.928		&	0.838		& \textbf{	0.951	}		&	Equiv-D			& \textbf{	0.869	}	&	1.028			&	0.983		D	&	Equiv-D			& \textbf{	0.008	}	&	0.018		&	0.005		&	Equiv-D					\\
16	& \textbf{	0.903	}	&	0.715		&	0.870			&	Equiv-O			& \textbf{	0.846	}	&	0.899			&	0.960			&	Equiv-O			& \textbf{	0.011	}	&	0.032		&	0.014		&	Equiv-O					\\
32	& \textbf{	0.857	}	&	0.655		&	0.737			&	0.824			& \textbf{	0.845	}	&	0.879			&	0.873		D	&	0.881	DO		& \textbf{	0.016	}	&	0.039		&	0.030		&	0.019					\\
64	& \textbf{	0.796	}	&	0.632		&	0.662			&	0.761			& \textbf{	0.859	}	&	0.887			&	0.885		D	&	0.879	BDO		& \textbf{	0.023	}	&	0.042		&	0.038		&	0.027					\\
128	& \textbf{	0.738	}	&	0.620		&	0.633			&	0.705			& \textbf{	0.882	}	&	0.968			& \textbf{	0.888	}	B	&	0.911			& \textbf{	0.029	}	&	0.044		&	0.042		&	0.033					\\ \hline
\multicolumn{13}{|c|}{ZDT6}																																													\\ \hline
8	&	0.268		&	0.223		& \textbf{	0.298	}		&	Equiv-D			& \textbf{	0.988	}	& \textbf{	0.972	}	B	& \textbf{	0.996	}	B	&	Equiv-D			& \textbf{	0.173	}	&	0.191		&	0.160		&	Equiv-D					\\
16	& \textbf{	0.243	}	&	0.113		&	0.219			&	Equiv-O			& \textbf{	0.995	}	& \textbf{	0.987	}	B	& \textbf{	0.987	}	BD	&	Equiv-O			& \textbf{	0.184	}	&	0.240		&	0.193		&	Equiv-O					\\
32	& \textbf{	0.196	}	&	0.071		&	0.115			&	0.162			& \textbf{	0.998	}	& \textbf{	0.989	}	B	& \textbf{	0.988	}	BD	&	1.005	B		& \textbf{	0.204	}	&	0.257		&	0.238		&	0.220					\\
64	& \textbf{	0.145	}	&	0.056		&	0.075			&	0.120			&	0.996		&	0.986		B	& \textbf{	0.983	}	D	&	0.998	B		& \textbf{	0.226	}	&	0.264		&	0.255		&	0.235					\\
128	& \textbf{	0.104	}	&	0.049		&	0.055			&	0.084			&	0.993		&	1.007			& \textbf{	0.979	}		&	0.998	BD		& \textbf{	0.244	}	&	0.266		&	0.263		&	0.251					\\ \hline

\end{tabular}
}
\caption{Average quality metrics obtained after 30 runs per
  configuration, for the 4 methods compared: baseline (B), disjoint
  (D), overlapped (O) and automatically overlapped
  (A), % No sera mejor "automatically overlapped" or "automatic
       % overlap"? This does not sound good - JJ FERGU: Done
  using a chromosome length of 512 dimensions. Acronyms next to values
  indicate that there is \textcolor{blue}{no} significant difference with respect to
  that method for that value. Best values are marked in
  bold. Equiv-$X$ implies that value is the same as executing $X$,
  since both configurations would be the same.}  
\label{tab:results512}
\end{table*}



The average results for each configuration are shown in
Table \ref{tab:results512} (for 512 dimensions) and Table
\ref{tab:results2048} (for 2048). As previously explained, when $P=8$
the results of A are equivalent to the obtained by D (because
$c=0$), and when $P=16$ they are equivalent to O ($c=1$). This equivalence \textcolor{blue}{is referred} with the word {\em Equiv-} in tables. For example, Equiv-D in an HV cell  means that the HV of A is the same than the value in D column, because the behaviour of this configuration is the same than executing D.


\begin{table*}
\centering
\resizebox{13cm}{!}{
\begin{tabular}{|c||c|c|c|c||c|c|c|c||c|c|c|c||}
\hline
	&	\multicolumn{4}{|c|}{HV}													&	\multicolumn{4}{|c|}{Spread}														&	\multicolumn{4}{|c|}{IGD}														\\ \hline

\#Island	&	B		&	D		&	O			&	A			&	B		&	D			&	O			&	A			&	B		&	D		&	O		&	A					\\ \hline
\multicolumn{13}{|c|}{ZDT1}																																													\\ \hline
8	&	0.891		& \textbf{	0.953	}	&	0.937			&	Equiv-D			& \textbf{	0.681	}	& \textbf{	0.635	}	B	&	0.661		D	&	Equiv-D			&	0.015		& \textbf{	0.002	}	&	0.005		&	Equiv-D					\\
16	&	0.884		&	0.850		& \textbf{	0.942	}		&	Equiv-O			& \textbf{	0.705	}	&	0.908			& \textbf{	0.670	}	B	&	Equiv-O			&	0.016		&	0.022		& \textbf{	0.004	}	&	Equiv-O					\\
32	&	0.851		&	0.674		&	0.859		B	& \textbf{	0.900	}		& \textbf{	0.754	}	&	0.868			&	0.826		D	& \textbf{	0.763	}	B	&	0.023		&	0.062		&	0.020	B	& \textbf{	0.012	}				\\
64	& \textbf{	0.800	}	&	0.608		&	0.697			& \textbf{	0.824	}	B	& \textbf{	0.808	}	&	0.880			& \textbf{	0.861	}	B	& \textbf{	0.823	}	B	&	0.033		&	0.078		&	0.056		& \textbf{	0.027	}				\\
128	&	0.735		&	0.582		&	0.613			& \textbf{	0.745	}		& \textbf{	0.841	}	&	0.888			&	0.878		D	&	0.865		O	&	0.047		&	0.084		&	0.075		& \textbf{	0.043	}				\\ \hline
\multicolumn{13}{|c|}{ZDT2}																																													\\ \hline
8	&	0.832		& \textbf{	0.895	}	&	0.869			&	Equiv-D			& \textbf{	0.849	}	& \textbf{	0.886	}	B	&	0.853		D	&	Equiv-D			&	0.023		& \textbf{	0.006	}	&	0.013		&	Equiv-D					\\
16	&	0.831		&	0.833	B	& \textbf{	0.884	}		&	Equiv-O			& \textbf{	0.810	}	&	1.001			& \textbf{	0.802	}	B	&	Equiv-O			&	0.023		&	0.022	B	& \textbf{	0.009	}	&	Equiv-O					\\
32	&	0.800		&	0.628		&	0.800		B	& \textbf{	0.817	}		& \textbf{	0.848	}	&	0.974			&	0.983		D	&	0.908			&	0.031		&	0.082		&	0.032	B	& \textbf{	0.027	}				\\
64	& \textbf{	0.729	}	&	0.491		&	0.623			&	0.716			& \textbf{	0.909	}	&	0.967			&	0.979		D	& \textbf{	0.997	}	BD	& \textbf{	0.052	}	&	0.121		&	0.084		& \textbf{	0.055	}	B			\\
128	& \textbf{	0.630	}	&	0.441		&	0.500			& \textbf{	0.614	}	B	& \textbf{	0.957	}	&	0.989			&	0.978		D	& \textbf{	0.994	}	BO	& \textbf{	0.080	}	&	0.136		&	0.119		& \textbf{	0.085	}	B			\\ \hline
\multicolumn{13}{|c|}{ZDT3}																																													\\ \hline
8	&	0.917		& \textbf{	0.971	}	&	0.960			&	Equiv-D			& \textbf{	0.843	}	& \textbf{	0.854	}	B	&	0.868		D	&	Equiv-D			&	0.009		& \textbf{	0.001	}	&	0.004		&	Equiv-D					\\
16	&	0.911		&	0.876	B	& \textbf{	0.963	}		&	Equiv-O			& \textbf{	0.864	}	&	0.899		B	& \textbf{	0.837	}	B	&	Equiv-O			&	0.010		&	0.014		& \textbf{	0.003	}	&	Equiv-O					\\
32	&	0.884		&	0.710		&	0.883		B	& \textbf{	0.931	}		& \textbf{	0.856	}	& \textbf{	0.870	}	B	& \textbf{	0.842	}	B	& \textbf{	0.842	}	BDO	&	0.013		&	0.032		&	0.013	B	& \textbf{	0.008	}				\\
64	&	0.828		&	0.645		&	0.728			& \textbf{	0.854	}		& \textbf{	0.878	}	& \textbf{	0.896	}	B	& \textbf{	0.871	}	BD	& \textbf{	0.873	}	BDO	& \textbf{	0.019	}	&	0.040		&	0.030		& \textbf{	0.016	}	B			\\
128	& \textbf{	0.770	}	&	0.620		&	0.651			& \textbf{	0.773	}	B	& \textbf{	0.887	}	& \textbf{	0.901	}	B	& \textbf{	0.890	}	BD	& \textbf{	0.885	}	BDO	& \textbf{	0.026	}	&	0.043		&	0.039		& \textbf{	0.025	}	B			\\ \hline
\multicolumn{13}{|c|}{ZDT6}																																													\\ \hline
8	&	0.271		& \textbf{	0.398	}	&	0.323			&	Equiv-D			& \textbf{	0.982	}	& \textbf{	0.982	}	B	&	0.994			&	Equiv-D			&	0.171		& \textbf{	0.115	}	&	0.149		&	Equiv-D					\\
16	&	0.275		&	0.295	B	& \textbf{	0.354	}		&	Equiv-O			& \textbf{	0.981	}	& \textbf{	0.970	}	B	&	1.006			&	Equiv-O			&	0.170		&	0.161	B	& \textbf{	0.136	}	&	Equiv-O					\\
32	&	0.239		&	0.123		&	0.240			& \textbf{	0.254	}		& \textbf{	0.989	}	& \textbf{	0.991	}	B	& \textbf{	0.982	}	BD	& \textbf{	0.999	}	BD	&	0.186		&	0.235		&	0.185	B	& \textbf{	0.179	}				\\
64	& \textbf{	0.184	}	&	0.068		&	0.125			& \textbf{	0.178	}	B	& \textbf{	0.985	}	& \textbf{	0.982	}	B	& \textbf{	0.992	}	B	& \textbf{	0.995	}	BO	& \textbf{	0.209	}	&	0.259		&	0.235		&	0.212					\\
128	& \textbf{	0.128	}	&	0.051		&	0.071			& \textbf{	0.124	}	B	& \textbf{	0.991	}	& \textbf{	0.992	}	B	& \textbf{	0.988	}	BD	&	1.003			& \textbf{	0.233	}	&	0.266		&	0.257		& \textbf{	0.235	}	B			\\ \hline

\end{tabular}
}
\caption{Average quality metrics obtained after 30 runs per configuration, for the 4 methods compared: baseline (B), disjoint (D), overlapped (O) and automatically overlapped (A), using a chromosome length of 2048 dimensions. Acronyms next to values indicate that there is \textcolor{blue}{no} significant difference with respect to that method for that value. Best values are marked in bold. Equiv-$X$ implies that value is the same as executing $X$, since both configurations would be the same.}
\label{tab:results2048}
\end{table*}



%DESCRIPTION OF THE RESULTS
Results show that there is a difference in performance when using 512 or 2048 dimensions. Although in some cases the overlapped methods obtain quality metrics values better or significantly equal than those obtained by the baseline, it is clear that 512 dimensions \textcolor{blue}{are} not \textcolor{blue}{a large enough value} to apply these methods. A contradiction arises with respect to the results obtained in our previous work in a shared-memory mono-processor version \citep{Garcia16hpmoon}, where the overlapping method obtained better results than the baseline in both dimension lengths. This can be explained because the added migration latency between nodes of the cluster requires more time than the time saved during the crossover and migration. This was not a problem in the mono-processor version, where the individuals shared the same memory space.

However, with 2048 dimensions, results show that \textcolor{blue}{the division of} the chromosome produces an improvement in all the quality indicators using the automatic ($A$) version (Table \ref{tab:results2048}), even overcoming the overlapping ($O$) and disjoint ($D$) methods. Therefore, there exists some kind of limit point in chromosome length where one method will be preferable to another, besides depending on the number of islands and population size.


\begin{table*}[h!tb]
\centering
\resizebox{12cm}{!}{
\begin{tabular}{|c||c|c|c|c||c|c|c|c||}
\hline
	&	\multicolumn{4}{|c|}{Average solutions per front}													&	\multicolumn{4}{|c|}{Generations}															\\ \hline

\#Island	&	B		&	D		&	O			&	A			&	B		&	D			&	O			&	A				\\ \hline
\multicolumn{9}{|c|}{ZDT1}																				\\ \hline
8	&	182.700		&	128.500		&	158.167			&	Equiv-D			&	397.367		&	776.967			&	603.667			&	Equiv-D				\\
16	&	132.567		&	43.633		&	76.167			&	Equiv-O			&	567.933		&	908.467			&	838.000			&	Equiv-O				\\
32	&	102.200		&	37.533		&	34.133	D		&	52.033			&	731.067		&	959.067			&	938.167			&	917.000				\\
64	&	81.100		&	46.267		&	26.300			&	30.167		O	&	846.733		&	978.733			&	972.567			&	927.133	B			\\
128	&	77.167		&	57.767		&	35.767			&	29.167		O	&	923.133		&	984.767			&	984.233	D		&	967.933				\\ \hline
\multicolumn{9}{|c|}{ZDT2}																															\\ \hline
8	&	122.700		&	91.633		&	108.833	BD		&	Equiv-D			&	398.167		&	772.000			&	605.100			&	Equiv-D				\\
16	&	94.867		&	28.033		&	62.467			&	Equiv-O			&	574.567		&	908.433			&	840.900			&	Equiv-O				\\
32	&	56.633		&	11.433		&	19.467	D		&	31.567			&	735.867		&	960.167			&	939.200			&	904.900				\\
64	&	33.467		&	10.267		&	9.367	D		&	19.067			&	849.900		&	978.600			&	972.167			&	929.800	B			\\
128	&	22.833		&	12.633		&	7.800			&	13.967		D	&	929.433		&	984.567			&	984.233	D		&	971.700				\\ \hline
\multicolumn{9}{|c|}{ZDT3}																															\\ \hline
8	&	212.900		&	129.233		&	171.367			&	Equiv-D			&	398.633		&	776.000			&	603.333			&	Equiv-D				\\
16	&	176.133		&	43.567		&	90.100			&	Equiv-O			&	573.033		&	908.667			&	838.000			&	Equiv-O				\\
32	&	121.500		&	42.800		&	33.200			&	56.900			&	733.233		&	959.000			&	937.967			&	918.833				\\
64	&	96.500		&	54.267		&	34.900			&	37.800		O	&	849.200		&	977.167			&	972.200			&	933.167				\\
128	&	76.700		&	62.200		&	41.767			&	33.867		D	&	924.000		&	984.733			&	984.367	D		&	966.433				\\ \hline
\multicolumn{9}{|c|}{ZDT6}																															\\ \hline
8	&	42.233		&	28.633		&	35.967	BD		&	Equiv-D			&	396.900		&	773.400			&	603.533			&	Equiv-D				\\
16	&	43.733		&	7.733		&	18.967			&	Equiv-O			&	568.200		&	908.900			&	836.033			&	Equiv-O				\\
32	&	35.533		&	8.033		&	8.633	D		&	16.233		DO	&	735.700		&	958.900			&	938.600			&	926.167				\\
64	&	22.600		&	10.700		&	7.500	D		&	7.533		DO	&	850.267		&	978.067			&	972.467			&	940.267				\\
128	&	18.133		&	15.000	B	&	9.067			&	11.367		D	&	927.233		&	984.667			&	983.933	D		&	969.433				\\ \hline
\end{tabular}
}
\caption{Average number of generations and  solutions per front, obtained after 30 runs per configuration, for the 4 methods compared: baseline (B), disjoint (D), overlapped (O) and automatically overlapped (A), using a chromosome length of 512 dimensions. Acronyms next to values indicate that there is \textcolor{blue}{no} significant difference with respect to that method for that value. Equiv-$X$ implies that value is the same as executing $X$, since both configurations would be the same.}
\label{tab:sols512}
\end{table*}
%
\begin{table*}[h!tb]
\centering
\resizebox{12cm}{!}{
\begin{tabular}{|c||c|c|c|c||c|c|c|c||}
\hline
	&	\multicolumn{4}{|c|}{Average solutions per front}													&	\multicolumn{4}{|c|}{Generations}															\\ \hline
%\multicolumn{13}{|c|}{2048 dimensions}																															\\ \hline
\#Island	&	B		&	D		&	O			&	A			&	B		&	D			&	O			&	A				\\ \hline
\multicolumn{9}{|c|}{ZDT1}																					\\ \hline
8	&	137.733		&	47.167		&	119.933	B		&	Equiv-D			&	175.067		&	225.667			&	207.933			&	Equiv-D				\\
16	&	92.633		&	38.233		&	47.533	D		&	Equiv-O			&	204.867		&	238.533			&	232.900			&	Equiv-O				\\
32	&	56.167		&	41.167		&	28.667			&	32.567	O		&	225.433		&	243.833			&	242.533			&	242.000	O			\\
64	&	50.900		&	49.667	B	&	35.600			&	25.367			&	236.500		&	245.967			&	245.700			&	244.033	D			\\
128	&	45.767		&	64.933		&	44.167	B		&	31.867			&	242.800		&	247.000			&	247.000	D		&	245.733				\\ \hline
\multicolumn{9}{|c|}{ZDT2}																															\\ \hline
8	&	64.267		&	22.733		&	56.867	B		&	Equiv-D			&	175.633		&	226.000			&	208.100			&	Equiv-D				\\
16	&	52.300		&	10.733		&	20.067	D		&	Equiv-O			&	205.033		&	238.867			&	233.100			&	Equiv-O				\\
32	&	34.400		&	10.367		&	10.433	D		&	17.900	O		&	225.600		&	244.267			&	242.633			&	242.000	O			\\
64	&	24.600		&	10.900		&	9.267	D		&	12.867	DO		&	236.700		&	246.000			&	245.767			&	244.033	D			\\
128	&	18.667		&	17.833	B	&	10.367			&	12.933	O		&	243.367		&	247.000			&	247.000	d		&	245.833				\\ \hline
\multicolumn{9}{|c|}{ZDT3}																															\\ \hline
8	&	163.767		&	83.367		&	119.467			&	Equiv-D			&	176.533		&	226.400			&	207.700			&	Equiv-D				\\
16	&	108.467		&	49.433		&	47.700	D		&	Equiv-O			&	205.333		&	238.467			&	232.933			&	Equiv-O				\\
32	&	72.133		&	44.333		&	31.833			&	36.533	O		&	225.100		&	243.900			&	242.433			&	242.000	O			\\
64	&	54.867		&	57.600	B	&	40.633			&	29.300			&	236.333		&	245.933			&	245.733			&	244.000	D			\\
128	&	50.600		&	72.133		&	49.033	B		&	34.933			&	243.200		&	247.000			&	247.000	D		&	245.833				\\ \hline
\multicolumn{9}{|c|}{ZDT6}																															\\ \hline
8	&	22.133		&	13.833		&	14.433	D		&	Equiv-D			&	175.733		&	226.100			&	207.767			&	Equiv-D				\\
16	&	20.767		&	15.867		&	13.300	D		&	Equiv-O			&	205.033		&	238.433			&	232.933			&	Equiv-O				\\
32	&	22.600		&	10.700		&	10.033	D		&	11.967	DO		&	225.833		&	243.667			&	242.500			&	242.000	O			\\
64	&	19.033		&	11.267		&	10.533	D		&	10.567	DO		&	236.433		&	245.900			&	245.833			&	244.000	D			\\
128	&	15.800		&	24.500		&	11.600			&	12.233	DO		&	243.800		&	247.000			&	247.000	D		&	245.533				\\ \hline
\end{tabular}
}
\caption{Average number of generations and solutions per front after 30 runs per configuration, for methods baseline (B), disjoint (D), overlapped (O) and automatically overlapped (A), using a chromosome length of 2048 dimensions. Acronyms next to values indicate that there is \textcolor{blue}{no} significant difference with respect to that method for that value. Equiv-$X$ implies that value is the same as executing $X$, since both configurations would be the same.}
\label{tab:sols2048}
\end{table*}
%
%EXPLANATION OF THE RESULTS
This can be explained comparing the number of non-dominated solutions
of each front and the average number of generations (Table
\ref{tab:sols512} and Table \ref{tab:sols2048}).

With both chromosome
lengths, increasing the number of islands implies more generations
with all the methods (logically, as there are fewer individuals in each
island). But also, the SLA methods
approach to the number of generations \textcolor{blue}{executed by} the baseline when
increasing the number of islands. However, with $L=2048$ the migration
time is big enough  to not improve the number of generations
with respect to the baseline, even \textcolor{blue}{with} the lower number of islands, as
it happens with $L=512$. Therefore, more generations do not
necessarily mean \textcolor{blue}{an improvement in} the solution of the global PF, but focusing on
different elements of the chromosome. As previously stated, every
island is unaware of the other islands PFs, \textcolor{blue}{since} they are trying to
optimize their solutions independently.

With respect to the average
number of solutions per front, there is a clear difference 
 with the baseline with $L=512$, where this value is in most
cases, less than a half. The number of non-dominated solutions
also implies a better Spread indicator, where the baseline 
 obtains better (or not significantly different) values in the majority of the compared configurations.



%ZDT1
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt1_512.png}
\caption{PFs obtained in one arbitrary run for the ZDT1 problem with a chromosome size ($L$) of 512 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt1_512}
\end{figure}
%
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt1_2048.png}
\caption{PFs obtained in one arbitrary run for the ZDT1 problem with a chromosome size ($L$) of 2048 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt1_2048}
\end{figure}
%
%ZDT2
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt2_512.png}
\caption{PFs obtained in one arbitrary run for the ZDT2 problem with a chromosome size ($L$) of 512 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt2_512}
\end{figure}
%
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt2_2048.png}
\caption{PFs obtained in one arbitrary run for the ZDT2 problem with a chromosome size ($L$) of 2048 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt2_2048}
\end{figure}
%
%ZDT3
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt3_512.png}
\caption{PFs obtained in one arbitrary run for the ZDT3 problem with a chromosome size ($L$) of 512 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt3_512}
\end{figure}
%
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt3_2048.png}
\caption{PFs obtained in one arbitrary run for the ZDT3 problem with a chromosome size ($L$) of 2048 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt3_2048}
\end{figure}
%
%
%
%ZDT6
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt6_512.png}
\caption{PFs obtained in one arbitrary run for the ZDT6 problem with a chromosome size ($L$) of 512 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt6_512}
\end{figure}
%
\begin{figure}[h!tb]
\centering
\includegraphics[width=12cm]{plot_zdt6_2048.png}
\caption{PFs obtained in one arbitrary run for the ZDT6 problem with a chromosome size ($L$) of 2048 for each combination of number of islands ($P$) and method: baseline ($B$), disjoint ($D$), overlapped ($O$) and automatic overlapped ($A$). Results for 8 and 16 islands of $A$ are equivalent of running $D$ and $O$ respectively. }
\label{fig:plot_zdt6_2048}
\end{figure}




%%%%%%FERGU: WARNING, THIS SECTION IS STILL SHIT
%ZDT1 
After establishing the performance of the new method and in order to
have some insight on how they work, the effect of the different chromosome sizes and \textcolor{blue}{the} number of
islands can be checked. Plotting the solution sets allows to observe its quality, distribution and shape, \textcolor{blue}{especially} if they are limited to 2 or 3 objectives \cite{Li17read}, as in this paper.  Figures \ref{fig:plot_zdt1_512} to \ref{fig:plot_zdt6_2048} show the
final PFs of one arbitrary sample run of each combination. The first
one, ZDT1, has a convex Pareto-optimal front. Comparing results from
$L=512$ (Figure \ref{fig:plot_zdt1_512}) and $L=2048$ (Figure
\ref{fig:plot_zdt1_2048}) it is apparent that the quality of the
generated PFs depends on the chromosome size. Specifically, all
configurations  with
$L=512$  seem to have a worse Spread and HV. On the other hand, the
SLA methods behave worse than $B$, as it was also shown on average in
Table \ref{tab:results512}. Nevertheless, \textcolor{blue}{when focusing} on the plots
obtained with $L=2048$ (Figure \ref{fig:plot_zdt1_2048}) this
difference is less clear. Figure \ref{fig:plot_zdt1_2048} shows that
solutions obtained by the SLA methods show higher dispersion than the
baseline as $P$ grows. However, with $A$, the area covered by the PF
is still larger.

%ZDT2
ZDT2 has a non-convex Pareto front. From Figures
\ref{fig:plot_zdt2_512} and \ref{fig:plot_zdt2_2048} it is clear that, as in the previous problem ZDT1, there is a decrease of quality for all configurations as the size of $P$ increases.  Nevertheless, there is not a clear decrease in the PF quality \textcolor{blue}{for this benchmark}, when $L$ goes from 512 to 2048.

%ZDT3
ZDT3 Pareto-optimal front is formed by non-contiguous convex parts. Plots for both chromosome sizes (Figures \ref{fig:plot_zdt3_512} and \ref{fig:plot_zdt3_2048}) show solutions gathered in similar regions in all configurations. However, with $L=512$, the rightmost part of the obtained non-dominated solutions is not obtained in the $A$ alternative with $P=8$  and $P=16$ (being equivalent to alternatives $O$ and $D$). This explains why\textcolor{blue}{,} with this chromosome length, the SLA methods do not improve the results obtained by $B$. This problem does not appear when $L=2048$. Although the differences in the Spread metric are not significant for the different alternatives for this benchmark, (as shown in Table \ref{tab:results2048}), the HV and IGD metrics can be used to show the effectiveness of our approach in this type of problem with non-continuous PFs.

In ZDT6, the Pareto-optimal solutions are not only non-uniformly distributed along the PF, but their density also increases \textcolor{blue}{when moving} further away from it. That is the reason why some PFs obtained have an extremely low number of solutions in some configurations, and also, they are aggregated \textcolor{blue}{towards} areas with more density. Moreover, all configurations, including $B$, obtained PFs relatively far away from the optimal PF, as opposed as in previous problems. Spread is very similar for all methods $B$, $D$, $O$and $A$ across different $L$ sizes. Indeed, there is \textcolor{blue}{no} a significant difference between methods, with an exception: Spread using $A$ with $L=512$ is significantly worse. As in previous approaches, it is visually clear that increasing the number of islands, and therefore, reducing the number of individuals per island, implies a decrease  in \textcolor{blue}{the} quality of the HV.

Finally, as it was already observed in \citep{Garcia16hpmoon}, all the performance indicators show worse values as the number of islands increases, and so the  sizes of the subpopulations are smaller. This is consistent with the claim by Dorronsoro et al. \citep{Dorronsoro13superlinear}, who found that cooperative co-evolutionary MOEAs work better on bigger populations (more than 100 individuals).


%%%%REAL PROBLEM
%\subsection{Real problem benchmark: Unsupervised Feature Selection}
%\textcolor{red}{A real problem has also been used to BLABLABLA. In this case, the problem used to solve is the unsupervised feature selection. A dataset formed by EEG signals from Brain Computer Interface (BCI) is used as a benchmark \cite{Kimovski15Parallel}, due to the required high computational cost and chromosome length. Individuals in this case are binary vectors indicating if a specific feature is selected or not. To evaluate a set of features different clustering validation indexes (CVIs) can be used.}

%\textcolor{red}{In this case, the two objectives to compare the three methods are the inter-cluster separation ($f1$) and the intra-cluster separation ($f2$). To obtain this measures, and after applying the projection to the dataset, a method based in the one presented  \cite{Kimovski15Parallel} is applied. Starting with a random value of the projection, the distance to the closer one is stored, and so on. After ordering these distances from lower to higher, we consider the intra-cluster distance ($f1$) as the one in the position 1/4 of the list, while the inter-cluster ($f2$) distance is in the position 3/4. The intra-cluster distance objective needs to be minimized, while the inter-cluster is maximized. Figure \ref{fig:cvis} explains this method using a extremely simplified example. Note that the goal of this paper is not obtain better CVI values than other methods, but to study the different overlapping schemes in parallel MOEAs.}

%\begin{figure}
%\centering
%\includegraphics[width=10cm]{clusterCVI.pdf}
%\caption{\textcolor{red}{Method to calculate the two objectives for the Feature Selection problem. Starting from a random $d$ point of the projection of the features, the distance to the closer point is calculated iteratively. After ordering these distances, the one in the position 1/4 (a) is considered the intra-cluster distance, while the one in position 3/4 (b) is considered the inter-cluster one.}}
%\label{fig:cvis}
%\end{figure}


%\textcolor{red}{The Dataset used is ... Due to the high computational cost required for the fitness function, the running time for each run has been set to 4 hours, with two generations before sending the individual to another random island. Table \ref{tab:parametersBCI} summarizes the specific parameters for this experiment (the rest of the parameters are the same than the previous experiment, shown in Table \ref{tab:parameters} ). As there is no optimal PF known for this problem, we have used the paretos obtained from all runs to obtain the optimal PF to apply the IGD quality metric.}

%\textcolor{red}{
%\begin{table*}
%\begin{center}
%\begin{tabular}{|c|c|}
%\hline
%{\em Parameter Name} & {\em Value} \\ \hline
%Number of islands ($P$) & 8, 32 and 128 \\ \hline
%Chromosome size ($L$) & 3600 \\ \hline
%Crossover type & One-point \\ \hline
%Mutation  type & flip\\ \hline
%Generations between migration & 2 \\ \hline
%Runs per configuration & 10 \\ \hline
%\end{tabular}
%\caption{\textcolor{red}{Parameters and operators used in the experiments for Feature Selection problem (the rest of the parameters are the ones described in Table \ref{tab:parameters}).}}
%\label{tab:parametersBCI}
%\end{center}
%\end{table*}
%}






\section{Conclusions}

Problems that require high-performance 
 and deal with a large number of decision variables can leverage the
 division of the decision space that parallel and distributed
 algorithms imply. This can be done in dMOEAs by selective operator application (SLA), that is, dividing the
 chromosome into different parts, each one modified by a different
 island. This paper compares a baseline distributed NSGA-II with three
 different strategies to separate the chromosome (disjoint or
 overlapping parts), using a high number of islands. Results show that
 these methods can achieve better quality metrics than the baseline in
 the same amount of time, with large chromosome lengths. 

Obtained results also show that when the number of islands
\textcolor{blue}{is increased}, the
automatic overlapping method ($A$) significantly improves the results with
respect to the disjoint and overlapped methods. However, this is only
apparent with larger chromosome sizes. Therefore, the length of the
chromosome is also a key factor to take into account in automatic overlapping
methods, and not only the number of islands. 
%Studying this factor with more types of problems, and new configurations of population size and chromosome lengths could be addressed in the future. 
Since our method divides the individuals into blocks of divisible
size, aggregation methods after migration, such as the ones used in
\cite{Kimovski15Parallel} or \cite{Dorronsoro13superlinear} can be
also tested. But as complete individuals \textcolor{blue}{are treated} in
each island, the possibility of using a real number, such as 0.3 (30\%
overlapping) instead \textcolor{blue}{of} an integer value opens future experimental
setups. \textcolor{blue}{This should also take care of epistatic
  interactions between chromosome sizes: although variation operators
  operate on chromosome fragments, selection and fitness evaluation
  operates on the whole chromosome; besides, there is migration
  between islands, so the probability of reaching local minima due to
  this fact is, in fact, going to be avoided.}
For example, comparing 
different ways to calculate $c$ using linear, logarithmic or exponential functions
depending on population size, number of islands, or other values, or
using some statistical parameter setting method, such as Taguchi's
\cite{Keratmatpour2018Taguchi}. \textcolor{blue}{However, taking into
  account that the linear change tested in this paper in fact obtains
  good results with a simple formula, it is our conclusion that
  further complication would not be necessary.}

Although the results obtained in this work are promising, it is clear
that this method requires more future experiments. These new
experiments should involve a more complete parameter study, including
a sensitivity analysis, to validate our approach. Other benchmarks and
real problems should be addressed in the future. These problems could
involve dealing with more than two objectives, so polar coordinates
should be used to visually understand the results
\cite{Li17read}. Also, other MOEA algorithms available in the
literature, such as SPEA or MOEA/D could also be compared. 


% Moreover, a diversity analysis of the individuals in each island during the algorithm run could be carried out to understand its influence on the results.

% 
% More discussion should be added. Why is adaptive better? Is the high
% performance really needed? - JJ
% STILL more discussion should be needed. For instance, the last
% paragraph of results begs an explanation of the influence of diversity on
% results - JJ Pablo: extending this section

Finally, more distributed implementations in several systems (such as a
GPUs or heterogeneous clusters) with different amounts of
islands/processors, could be used to perform a scalability study of the
different methods, being the transmission time between islands a
relevant issue to be addressed.



\section*{Acknowledgements}

This work has been partially funded by project SPIP2017-02116 (Spanish ``Direcci\'on General de Tr\'afico''), and projects, TIN2015-67020-P, DeepBio TIN2017-85727-C4-2-P  and TEC2015-68752 (Spanish ``Ministerio de
Econom{\'ia}a y Competitividad'') and PGC2018-098813-B-C31 (Spanish ``Ministerio de Ciencia, Innovacin y Universidades''), and by European Regional Development Funds (ERDF).
We would like to express our gratitude to the editorial team and the reviewers, whose valuable comments on this paper have significantly improved its quality.

\section*{References}

%\bibliographystyle{elsarticle-num}
%\bibliography{hpmoon-asoco}
\begin{thebibliography}{10}
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{Gong15models}
Y.~Gong, W.~Chen, Z.~Zhan, J.~Zhang, Y.~Li, Q.~Zhang, J.~Li, Distributed
  evolutionary algorithms and their models: {A} survey of the state-of-the-art,
  Appl. Soft Comput. 34 (2015) 286--300.

\bibitem{Alba02Parallelism}
E.~Alba, M.~Tomassini, Parallelism and evolutionary algorithms, {IEEE} Trans.
  Evolutionary Computation 6~(5) (2002) 443--462.

\bibitem{Mora13paretobased}
A.~M. Mora, P.~Garc{\'{\i}}a{-}S{\'{a}}nchez, J.~J. Merelo-Guerv{\'{o}}s, P.~A.
  Castillo, Pareto-based multi-colony multi-objective ant colony optimization
  algorithms: an island model proposal, Soft Comput. 17~(7) (2013) 1175--1207.

\bibitem{LIU2017344}
Y.~Liu, D.~Gong, X.~Sun, Y.~Zhang, Many-objective evolutionary optimization
  based on reference points, Appl. Soft Comput. 50 (2017) 344 -- 355.

\bibitem{Luna15Survey}
F.~Luna, E.~Alba, Parallel multiobjective evolutionary algorithms, in:
  J.~Kacprzyk, W.~Pedrycz (Eds.), Springer Handbook of Computational
  Intelligence, Springer, 2015, pp. 1017--1031.

\bibitem{Mukhopadhyay14Survey}
A.~Mukhopadhyay, U.~Maulik, S.~Bandyopadhyay, C.~A.~C. Coello, A survey of
  multiobjective evolutionary algorithms for data mining: Part {I}, {IEEE} T.
  Evolut. Comput. 18~(1) (2014) 4--19.

\bibitem{Chavez15MO}
F.~C. de~la O, E.~Clemente, D.~E. Hern{\'{a}}ndez, F.~F. de~Vega, G.~Olague, A
  multi-objective evolutionary algorithm for interaction systems based on laser
  pointers, in: A.~M. Mora, G.~Squillero (Eds.), Applications of Evolutionary
  Computation - 18th European Conference, EvoApplications 2015, Copenhagen,
  Denmark, April 8-10, 2015, Proceedings, Vol. 9028 of Lecture Notes in
  Computer Science, Springer, 2015, pp. 504--516.

\bibitem{Hidalgo16residualstress}
J.~I. Hidalgo, R.~Fern{\'{a}}ndez, J.~M. Colmenar, F.~Cioffi, J.~L.
  Risco{-}Mart{\'{\i}}n, G.~Gonz{\'{a}}lez{-}Doncel, Using evolutionary
  algorithms to determine the residual stress profile across welds of
  age-hardenable aluminum alloys, Appl. Soft Comput. 40 (2016) 429--438.
\textcolor{blue}{
\bibitem{KAUR2018183}
M.~Kaur, S.~Kadam, A novel multi-objective bacteria foraging optimization
  algorithm ({MOBFOA}) for multi-objective scheduling, Appl. Soft Comput. 66
  (2018) 183 -- 195.
}
\textcolor{blue}{
\bibitem{XU2018268}
Y.~Xu, O.~Ding, R.~Qu, K.~Li, Hybrid multi-objective evolutionary algorithms
  based on decomposition for wireless sensor network coverage optimization,
  Appl. Soft Comput. 68 (2018) 268 -- 282.
}

\bibitem{DBLP:series/ncs/EibenS15}
A.~E. Eiben, J.~E. Smith, Introduction to Evolutionary Computing, Natural
  Computing Series, Springer, 2015.

\bibitem{TalbiUnified2018}
E.-G. Talbi,
  A
  unified view of parallel multi-objective evolutionary algorithms, J.
  Parallel Distrib. Comput. (2018) --In press.

\bibitem{Dorronsoro13superlinear}
B.~Dorronsoro, G.~Danoy, A.~J. Nebro, P.~Bouvry, Achieving super-linear
  performance in parallel multi-objective evolutionary algorithms by means of
  cooperative coevolution, Computers {\&} {OR} 40~(6) (2013) 1552--1563.

\bibitem{Deb00NSGAII}
K.~Deb, S.~Agrawal, A.~Pratap, T.~Meyarivan, A fast elitist non-dominated
  sorting genetic algorithm for multi-objective optimisation: {NSGA-II}, in:
  M.~Schoenauer, K.~Deb, G.~Rudolph, X.~Yao, E.~Lutton, J.~J.~M. Guerv{\'{o}}s,
  H.~Schwefel (Eds.), Parallel Problem Solving from Nature - {PPSN} VI, 6th
  International Conference, Paris, France, September 18-20, 2000, Proceedings,
  Vol. 1917 of Lecture Notes in Computer Science, Springer, 2000, pp. 849--858.

\bibitem{Alba13parallel}
E.~Alba, G.~Luque, S.~Nesmachnow, Parallel metaheuristics: recent advances and
  new trends, Int. T. Oper. Res. 20~(1) (2013) 1--48.

\bibitem{Folino03cellular}
G.~Folino, C.~Pizzuti, G.~Spezzano, A scalable cellular implementation of
  parallel genetic programming, {IEEE} Trans. Evolutionary Computation 7~(1)
  (2003) 37--53.

\bibitem{Branke04Parallelizingcone}
J.~Branke, H.~Schmeck, K.~Deb, R.~S. Maheshwar, Parallelizing multi-objective
  evolutionary algorithms: cone separation, in: Proceedings of the {IEEE}
  Congress on Evolutionary Computation, {CEC} 2004, 19-23 June 2004, Portland,
  OR, {USA}, {IEEE}, 2004, pp. 1952--1957.

\bibitem{Zhang17DECAL}
Y.~H. Zhang, Y.~J. Gong, T.~L. Gu, H.~Q. Yuan, W.~Zhang, S.~Kwong, J.~Zhang,
  Decal: Decomposition-based coevolutionary algorithm for many-objective
  optimization, IEEE T. Cybernetics (2017) 1--15.

\bibitem{Tonda12cooperative}
A.~P. Tonda, E.~Lutton, G.~Squillero, A benchmark for cooperative coevolution,
  Memet. Comput. 4~(4) (2012) 263--277.

\bibitem{Kimovski15Parallel}
D.~Kimovski, J.~Ortega, A.~Ortiz, R.~Ba{\~{n}}os, Parallel alternatives for
  evolutionary multi-objective optimization in unsupervised feature selection,
  Expert Syst. Appl. 42~(9) (2015) 4239--4252.

\bibitem{Jia19Coevo}
Y.~Jia, W.~Chen, T.~Gu, H.~Zhang, H.~Yuan, S.~Kwong, J.~Zhang,
  Distributed cooperative
  co-evolution with adaptive computing resource allocation for large scale
  optimization, {IEEE} Trans. Evolutionary Computation 23~(2) (2019) 188--202.

\bibitem{Garcia16hpmoon}
P.~Garc{\'{\i}}a{-}S{\'{a}}nchez, J.~Ortega, J.~Gonz{\'{a}}lez, P.~A. Castillo,
  J.~J. Merelo, Addressing high dimensional multi-objective optimization
  problems by coevolutionary islands with overlapping search spaces, in:
  G.~Squillero, P.~Burelli (Eds.), Applications of Evolutionary Computation -
  19th European Conference, EvoApplications 2016, Porto, Portugal, March 30 -
  April 1, 2016, Proceedings, Part {II}, Vol. 9598 of Lecture Notes in Computer
  Science, Springer, 2016, pp. 107--117.

\bibitem{Talbi08Parallel}
E.~Talbi, S.~Mostaghim, T.~Okabe, H.~Ishibuchi, G.~Rudolph, C.~A.~C. Coello,
  Parallel approaches for multiobjective optimization, in: J.~Branke, K.~Deb,
  K.~Miettinen, R.~Slowinski (Eds.), Multiobjective Optimization, Interactive
  and Evolutionary Approaches [outcome of Dagstuhl seminars]., Vol. 5252 of
  Lecture Notes in Computer Science, Springer, 2008, pp. 349--372.

\bibitem{Durillo08masterslave}
A.~J. Nebro, J.~J. Durillo, A study of the parallelization of the
  multi-objective metaheuristic {MOEA/D}, in: C.~Blum, R.~Battiti (Eds.),
  Learning and Intelligent Optimization, 4th International Conference, {LION}
  4, Venice, Italy, January 18-22, 2010. Selected Papers, Vol. 6073 of Lecture
  Notes in Computer Science, Springer, 2010, pp. 303--317.

\bibitem{Hiroyasu07discussion}
T.~Hiroyasu, K.~Yoshii, M.~Miki, Discussion of parallel model of
  multi-objective genetic algorithms on heterogeneous computational resources,
  in: H.~Lipson (Ed.), Genetic and Evolutionary Computation Conference, {GECCO}
  2007, Proceedings, London, England, UK, July 7-11, 2007, {ACM}, 2007, p. 904.

\bibitem{Deb03distributed}
K.~Deb, P.~Zope, A.~Jain, Distributed computing of {Pareto}-optimal solutions
  with evolutionary algorithms, in: C.~M. Fonseca, P.~J. Fleming, E.~Zitzler,
  K.~Deb, L.~Thiele (Eds.), Evolutionary Multi-Criterion Optimization, Second
  International Conference, {EMO} 2003, Faro, Portugal, April 8-11, 2003,
  Proceedings, Vol. 2632 of Lecture Notes in Computer Science, Springer, 2003,
  pp. 534--549.

\bibitem{Wang09parallel}
W.~Zhi-xin, G.~Ju, A parallel genetic algorithm in multi-objective
  optimization, in: Control and Decision Conference, 2009. CCDC '09. Chinese,
  2009, pp. 3497--3501.

\bibitem{Xiao03specialized}
N.~Xiao, M.~P. Armstrong, A specialized island model and its application in
  multiobjective optimization, in: E.~Cant{\'{u}}{-}Paz, J.~A. Foster, K.~Deb,
  L.~Davis, R.~Roy, U.~O'Reilly, H.~Beyer, R.~K. Standish, G.~Kendall, S.~W.
  Wilson, M.~Harman, J.~Wegener, D.~Dasgupta, M.~A. Potter, A.~C. Schultz,
  K.~A. Dowsland, N.~Jonoska, J.~F. Miller (Eds.), Genetic and Evolutionary
  Computation - {GECCO} 2003, Genetic and Evolutionary Computation Conference,
  Chicago, IL, USA, July 12-16, 2003. Proceedings, Part {II}, Vol. 2724 of
  Lecture Notes in Computer Science, Springer, 2003, pp. 1530--1540.

\bibitem{Martens13asynchronous}
M.~M{\"{a}}rtens, D.~Izzo, The asynchronous island model and {NSGA-II:} study
  of a new migration operator and its performance, in: C.~Blum, E.~Alba (Eds.),
  Genetic and Evolutionary Computation Conference, {GECCO} '13, Amsterdam, The
  Netherlands, July 6-10, 2013, {ACM}, 2013, pp. 1173--1180.
\textcolor{blue}{\bibitem{DorronsoroPSO2018}
A.~Atashpendar, B.~Dorronsoro, G.~Danoy, P.~Bouvry, A scalable parallel
  cooperative coevolutionary {PSO} algorithm for multi-objective optimization,
  J. Parallel Distrib. Comput. 112 (2018) 111--125.
}

\bibitem{CaoZLL17}
B.~Cao, J.~Zhao, Z.~Lv, X.~Liu, A distributed parallel cooperative
  coevolutionary multiobjective evolutionary algorithm for large-scale
  optimization, {IEEE} T. Ind. Inform. 13~(4) (2017) 2030--2038.

\bibitem{cheng2015adaptive}
R.~Cheng, Y.~Jin, K.~Narukawa, Adaptive reference vector generation for inverse
  model based evolutionary multiobjective optimization with degenerate and
  disconnected {Pareto} fronts, in: Evolutionary Multi-Criterion Optimization,
  Springer International Publishing, 2015, pp. 127--140.

\bibitem{LUO2017235}
J.~Luo, Q.~Liu, Y.~Yang, X.~Li, M.~rong Chen, W.~Cao, An artificial bee colony
  algorithm for multi-objective optimisation, Appl. Soft Comput. 50 (2017) 235
  -- 251.
\textcolor{blue}{
\bibitem{Keratmatpour2018Taguchi}
M.~Keramatpour, S.~T.~A. Niaki, S.~H.~R. Pasandideh, A bi-objective two-level
  newsvendor problem with discount policies and budget constraint, Comput. Ind.
  Eng. 120 (2018) 192 -- 205.
}

\bibitem{zdt2000a}
E.~Zitzler, K.~Deb, L.~Thiele, {Comparison of Multiobjective Evolutionary
  Algorithms: Empirical Results}, Evol. Comput. 8~(2) (2000) 173--195.

\bibitem{EVALUATIONPARALLEL}
E.~Alba, G.~Luque, Evaluation of parallel metaheuristics, in: L.~Paquete,
  M.~Chiarandini, D.~Basso (Eds.), Empirical Methods for the Analysis of
  Algorithms, Workshop EMAA 2006, Proceedings, Reykjavik, Iceland, 2006, pp.
  9--14.

\bibitem{cantu1998survey}
E.~Cant{\'u}-Paz, A survey of parallel genetic algorithms, Calculateurs
  paralleles, reseaux et systems repartis 10~(2) (1998) 141--171.

\bibitem{xiong2003parallel}
S.~Xiong, F.~Li, Parallel strength {Pareto} multi-objective evolutionary
  algorithm for optimization problems, in: Evolutionary Computation, 2003.
  CEC'03. The 2003 Congress on, Vol.~4, IEEE, 2003, pp. 2712--2718.

\bibitem{ECJ}
S.~Luke, et~al., {ECJ: A Java-based Evolutionary Computation and Genetic
  Programming Research System}, available at
  \url{http://www.cs.umd.edu/projects/plus/ec/ecj} (2009).

\bibitem{Durillo11Jmetal}
J.~J. Durillo, A.~J. Nebro, jmetal: {A} java framework for multi-objective
  optimization, Adv. Eng. Softw. 42~(10) (2011) 760--771.
\textcolor{blue}{
\bibitem{Li17read}
M.~Li, L.~Zhen, X.~Yao, How to read many-objective solution sets in parallel
  coordinates [educational forum], {IEEE} Comp. Int. Mag. 12~(4) (2017)
  88--100.
}
\end{thebibliography}




\end{document}
